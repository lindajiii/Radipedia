{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830a5293-6484-4acb-8900-01a45fe94a13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88350c2f-262c-4410-9718-9e75bb8acb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8902bb5-7e2b-46f9-ada3-76cac1594640",
   "metadata": {},
   "source": [
    "1. Calculate number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fc257d-81d8-4788-82cf-e9855affdbbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50452e38-612c-4775-98f7-43579a5e72c0",
   "metadata": {},
   "source": [
    "2. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f06e34-e215-42b0-b6f0-ca1044d6fda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size_tok = 2000 \n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size_tok, chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67735d1-894f-47e9-bd66-ca5ef27924f7",
   "metadata": {},
   "source": [
    "3. Raptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adbd35a-ee08-4512-a34f-bee9e66a9e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 14:00:30.893096: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import umap\n",
    "import umap.umap_ as umap\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "RANDOM_SEED = 224  # Fixed seed for reproducibility\n",
    "'''\n",
    "全局降维\n",
    "'''\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    - A numpy array of the embeddings reduced to the specified dimensionality.\n",
    "    \"\"\"\n",
    "    # 使用 UMAP 进行全局的维度降维处理。可以理解为将输入的高维嵌入映射到低维空间中。\n",
    "    # 参数:\n",
    "    # - embeddings: 输入的嵌入矩阵 (numpy array)。\n",
    "    # - dim: 目标维度，表示降维后嵌入的维度。\n",
    "    # - n_neighbors: 邻居的数量，默认为嵌入数量的平方根。\n",
    "    # - metric: 距离度量方法，默认为\"cosine\"。\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "\n",
    "'''\n",
    "局部降维\n",
    "'''\n",
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\" #initially 50\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Perform local dimensionality reduction on the embeddings using UMAP, typically after global clustering.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - dim: The target dimensionality for the reduced space.\n",
    "    - num_neighbors: The number of neighbors to consider for each point.\n",
    "    - metric: The distance metric to use for UMAP.\n",
    "\n",
    "    # 对嵌入执行局部降维，通常在全局聚类之后使用。\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of the embeddings reduced to the specified dimensionality.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)\n",
    "\n",
    "'''\n",
    "找到最佳的聚类数量\n",
    "'''\n",
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 10, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - max_clusters: The maximum number of clusters to consider.\n",
    "    - random_state: Seed for reproducibility.\n",
    "    # 使用贝叶斯信息准则 (BIC) 通过高斯混合模型 (GMM) 确定最佳聚类数。\n",
    "    # 该函数使用高斯混合模型（GMM）对嵌入进行聚类，并通过 贝叶斯信息准则（BIC） 来确定最佳的聚类数。\n",
    "    贝叶斯信息准则（Bayesian Information Criterion, BIC） 是一种统计学指标，用于模型选择。\n",
    "    它在评估统计模型时，平衡了模型的复杂度和拟合优度，帮助避免过拟合。BIC 的主要思想是：一个好的模型不仅应该很好地拟合数据，还应该尽量简洁。\n",
    "    Returns:\n",
    "    - An integer representing the optimal number of clusters found.\n",
    "    \"\"\"\n",
    "    max_clusters = min(max_clusters, len(embeddings))\n",
    "    n_clusters = np.arange(1, max_clusters)\n",
    "    bics = []\n",
    "    for n in n_clusters:\n",
    "        gm = GaussianMixture(n_components=n, random_state=random_state)\n",
    "        gm.fit(embeddings)\n",
    "        bics.append(gm.bic(embeddings)) ## 计算每个模型的 BIC 值\n",
    "    return n_clusters[np.argmin(bics)]  ## 选择 BIC 最小的聚类数\n",
    "\n",
    "\n",
    "'''\n",
    "使用GMM进行聚类\n",
    "'''\n",
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - threshold: The probability threshold for assigning an embedding to a cluster.\n",
    "    - random_state: Seed for reproducibility.\n",
    "\n",
    "     # 使用高斯混合模型（GMM）基于概率阈值对嵌入进行聚类。\n",
    "    Returns:\n",
    "    - A tuple containing the cluster labels and the number of clusters determined.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # 获得最佳聚类数\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state)\n",
    "    gm.fit(embeddings)\n",
    "    probs = gm.predict_proba(embeddings) # 获取每个embedding属于每个聚类的概率\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs] #基于阈值分配聚类，返回每个嵌入的聚类标签。\n",
    "    return labels, n_clusters\n",
    "\n",
    "\n",
    "'''\n",
    "执行聚类\n",
    "'''\n",
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform clustering on the embeddings by first reducing their dimensionality globally, then clustering\n",
    "    using a Gaussian Mixture Model, and finally performing local clustering within each global cluster.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings: The input embeddings as a numpy array.\n",
    "    - dim: The target dimensionality for UMAP reduction.\n",
    "    - threshold: The probability threshold for assigning an embedding to a cluster in GMM.\n",
    "\n",
    "\n",
    "    # 首先对嵌入数据进行全局降维、全局聚类，然后在每个全局聚类内进行局部降维和局部聚类。\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - A list of numpy arrays, where each array contains the cluster IDs for each embedding.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # Avoid clustering when there's insufficient data\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # Global dimensionality reduction\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # Global clustering\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))] #空列表，用于存储每个数据点的局部聚类标签\n",
    "    total_clusters = 0 #当前总聚类数\n",
    "\n",
    "    # Iterate through each global cluster to perform local clustering\n",
    "    for i in range(n_global_clusters):  # 遍历每个全局聚类并执行局部聚类\n",
    "        # Extract embeddings belonging to the current global cluster\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ] # 找到该全局聚类中的所有数据点\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # Handle small clusters with direct assignment\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # 如果数据点足够多，首先调用 local_cluster_embeddings 函数，对这些数据点执行局部降维。\n",
    "            # 然后再使用 GMM_cluster 进行局部聚类。\n",
    "            # Local dimensionality reduction and clustering\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # Assign local cluster IDs, adjusting for total clusters already processed\n",
    "        # 为每个局部聚类分配标签\n",
    "        # 在每个局部聚类内，首先找到局部聚类 j 中的嵌入点。\n",
    "        # 然后使用 np.where 函数找出原始嵌入中对应的索引位置，并将局部聚类标签 j + total_clusters 赋给这些数据点。\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters\n",
    "\n",
    "\n",
    "def embed(texts):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of text documents.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: An array of embeddings for the given text documents.\n",
    "    \"\"\"\n",
    "    text_embeddings = embd.encode(texts)\n",
    "    text_embeddings_np = np.array(text_embeddings)\n",
    "    print(\"text_embeddings_np\",text_embeddings_np.shape)\n",
    "    return text_embeddings_np\n",
    "\n",
    "'''\n",
    "生成embedding并聚类\n",
    "'''\n",
    "def embed_cluster_texts(texts):\n",
    "    \"\"\"\n",
    "    Embeds a list of texts and clusters them, returning a DataFrame with texts, their embeddings, and cluster labels.\n",
    "\n",
    "    This function combines embedding generation and clustering into a single step. It assumes the existence\n",
    "    of a previously defined `perform_clustering` function that performs clustering on the embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - texts: List[str], a list of text documents to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the original texts, their embeddings, and the assigned cluster labels.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts)  # Generate embeddings\n",
    "    # 对生成的嵌入进行聚类，降维后的维度为 10，聚类阈值为 0.1。\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # Perform clustering on the embeddings\n",
    "    df = pd.DataFrame()  # Initialize a DataFrame to store the results\n",
    "    df[\"text\"] = texts  # Store original texts\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # Store embeddings as a list in the DataFrame\n",
    "    df[\"cluster\"] = cluster_labels  # Store cluster labels\n",
    "    return df\n",
    "\n",
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Formats the text documents in a DataFrame into a single string.\n",
    "\n",
    "    \"\"\"\n",
    "    unique_txt = df[\"text\"].tolist()\n",
    "    return \"--- --- \\n --- --- \".join(unique_txt)\n",
    "\n",
    "\n",
    "#20241111 - We will use llama3 or other methods here instead of gpt4o\n",
    "\n",
    "'''\n",
    "生成embedding--->聚类----->生成summary\n",
    "'''\n",
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - texts: A list of text documents to be processed.\n",
    "    - level: An integer parameter that could define the depth or detail of processing.\n",
    "\n",
    "    生成文本嵌入、基于相似性进行聚类，然后对每个聚类中的文本内容生成总结。\n",
    "\n",
    "    Returns:\n",
    "    - Tuple containing two DataFrames:\n",
    "      1. The first DataFrame (`df_clusters`) includes the original texts, their embeddings, and cluster assignments.\n",
    "      2. The second DataFrame (`df_summary`) contains summaries for each cluster, the specified level of detail,\n",
    "         and the cluster identifiers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed and cluster the texts, resulting in a DataFrame with 'text', 'embd', and 'cluster' columns\n",
    "    df_clusters = embed_cluster_texts(texts)\n",
    "    '''\n",
    "    df = pd.DataFrame()  # Initialize a DataFrame to store the results\n",
    "    df[\"text\"] = texts  # Store original texts\n",
    "    df[\"embd\"] = list(text_embeddings_np)  # Store embeddings as a list in the DataFrame\n",
    "    df[\"cluster\"] = cluster_labels  # Store cluster labels\n",
    "    '''\n",
    "\n",
    "    # Prepare to expand the DataFrame for easier manipulation of clusters\n",
    "    expanded_list = []\n",
    "\n",
    "    # Expand DataFrame entries to document-cluster pairings for straightforward processing\n",
    "    # 如果文本属于多个聚类，则将其扩展为多行，每行代表文本与一个聚类的关联。\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # Create a new DataFrame from the expanded list\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # Retrieve unique cluster identifiers for processing\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "#     # Summarization\n",
    "#     template = \"\"\"Here is a sub-set of LangChain Expression Language doc.\n",
    "\n",
    "#     LangChain Expression Language provides a way to compose chain in LangChain.\n",
    "\n",
    "#     Give a detailed summary of the documentation provided.\n",
    "\n",
    "#     Documentation:\n",
    "#     {context}\n",
    "#     \"\"\"\n",
    "    \n",
    "    #20241111 - modify the prompt to be more about radiology\n",
    "    \n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "\n",
    "        prompt = f\"\"\"Here is a sub-set of radiology documentation, which may include information from radiology books, system guides, or research papers.\n",
    "\n",
    "        This document contains radiology-related content, including imaging techniques, diagnostic criteria, system guidelines, and medical research findings.\n",
    "\n",
    "        Provide a detailed summary of the information provided, focusing on key concepts, diagnostic methods, and relevant findings in less than 50 words.\n",
    "\n",
    "        Documentation:\n",
    "        {formatted_txt}\n",
    "        \n",
    "        Summary:\n",
    "        \"\"\"\n",
    "        summaries.append(generate_response(prompt))\n",
    "\n",
    "\n",
    "    # Create a DataFrame to store summaries with their corresponding cluster and level\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary\n",
    "\n",
    "\n",
    "# 在每个递归层次中，对输入的文本执行嵌入、聚类和总结操作，将结果存储下来。\n",
    "# 如果当前层次的聚类数超过 1，并且还没有达到最大递归深度，则用当前层次的总结文本作为下一层次的输入，继续递归。\n",
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    # level：当前递归的层次，初始值为 1。\n",
    "    # n_levels：最大递归深度，默认是 3。\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - texts: List[str], texts to be processed.\n",
    "    - level: int, current recursion level (starts at 1).\n",
    "    - n_levels: int, maximum depth of recursion.\n",
    "    Returns:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], a dictionary where keys are the recursion\n",
    "      levels and values are tuples containing the clusters DataFrame and summaries DataFrame at that level.\n",
    "    \"\"\"\n",
    "    results = {}  # Dictionary to store results at each level\n",
    "\n",
    "    # Perform embedding, clustering, and summarization for the current level\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level)\n",
    "\n",
    "    # Store the results of the current level\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # Determine if further recursion is possible and meaningful\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # Use summaries as the input texts for the next level of recursion\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # Merge the results from the next level into the current results dictionary\n",
    "        results.update(next_level_results)\n",
    "    # Dict[int, Tuple[pd.DataFrame, pd.DataFrame]] 返回的是一个字典的形式\n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_response(prompt):\n",
    "    torch.cuda.empty_cache()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=200,\n",
    "        do_sample=True,\n",
    "        temperature=0.3,\n",
    "        top_p=0.7,\n",
    "    )\n",
    "    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer_start = response_text.find(\"Summary:\\n\")\n",
    "    return response_text[answer_start + len(\"Summary:\\n\"):].strip() if answer_start != -1 else response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af3d0a-4b06-4363-8356-840d83218f4b",
   "metadata": {},
   "source": [
    "## Setup the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781e4f1f-763d-442f-8562-2160896766c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text_path = '/home/jupyter/project/VP_storage/extracted_paragraph_text.pkl'\n",
    "# table_path = '/home/jupyter/project/VP_storage/extracted_table_title.pkl' #set to \"\" if only text\n",
    "# figure_path = '/home/jupyter/project/VP_storage/extracted_figure_title.pkl' #set to \"\" if only text\n",
    "\n",
    "\n",
    "#text_path = '/home/jupyter/project/paper_text.pkl'\n",
    "#text_path = '/home/jupyter/project/data_book_text_book_text.pkl'\n",
    "#text_path = '/home/jupyter/project/data_system_guide_text_system_guide_text.pkl'\n",
    "table_path = ''\n",
    "figure_path = '/home/jupyter/project/lea_storage/book_image_caption_coordinated.pkl'\n",
    "\n",
    "\n",
    "specify_index_title_to_process = \"all\" #give index number (example : [0 , 1]) or \"all\"\n",
    "\n",
    "apply_chunking = False\n",
    "chunk_size_tok = 2000 \n",
    "\n",
    "collection_base_name = \"radiology_book_figures\"\n",
    "\n",
    "apply_raptor = False #change to false if don't want to apply raptor\n",
    "\n",
    "embedding_model_for_clustering = 'all-MiniLM-L6-v2' #using sentence transformer function\n",
    "llm_model_for_summarizing_cluster = \"meta-llama/Llama-3.2-1B-Instruct\" #will be loaded with quantized framework, alternative : \"aaditya/OpenBioLLM-Llama3-8B\" or other methods\n",
    "n_levels = 1 #number of levels for clustering\n",
    "\n",
    "embedding_model_for_retrieval = 'sentence-transformers/all-MiniLM-L6-v2' #using huggingface embedding function -- to push to milvus\n",
    "\n",
    "\n",
    "TOKEN = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "CLUSTER_ENDPOINT = \"https://xxxxxxxxxxxxxxxxxxxxxxxxxx.serverless.gcp-us-west1.cloud.zilliz.com\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097c4fe-18a9-45b6-9516-311ea6dee576",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup the LLM models and Milvus Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff2846-ce8c-4762-ae83-a4868c26adaf",
   "metadata": {},
   "source": [
    "1. Embedding for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684b1a15-e6c2-4878-8aab-73b8a52f4252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embd = SentenceTransformer(embedding_model_for_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a9987-9a2f-47dc-8f6a-60354ad4cb87",
   "metadata": {},
   "source": [
    "2. Model LLM for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59fd1e75-2f94-4bee-8fe2-c143aa3c5109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "def load_llama_model_quantized(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    \n",
    "    # Define quantization configuration for 8-bit or 4-bit\n",
    "    quantization_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,                     \n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    # Load the model with the specified quantization configuration\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",                    # Automatically allocate layers to GPU/CPU\n",
    "        torch_dtype=torch.float16,             # Use float16 for reduced memory usage on GPU\n",
    "        quantization_config=quantization_config,  # Pass the quantization config here\n",
    "        offload_folder=\"./VP_storage/offload/\" # Folder for offloaded parts if necessary\n",
    "    )\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = load_llama_model_quantized(llm_model_for_summarizing_cluster ) #change as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3bd2f-9f26-4f9b-98fe-3540daf096b2",
   "metadata": {},
   "source": [
    "3. Embedding for retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61801880-c718-4deb-9e49-ced7cc0c78fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2265759/2211427330.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(model_name=embedding_model_for_retrieval)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Milvus\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#embed_model = HuggingFaceEmbeddings(model_name=\"allenai/biomed_roberta_base\")\n",
    "embed_model = HuggingFaceEmbeddings(model_name=embedding_model_for_retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c34c2-c435-46ea-9377-38330f6835b7",
   "metadata": {},
   "source": [
    "4. Connect to Zillis Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "754a00a7-5d72-432a-8d76-fd7cbf8f1343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pymilvus import (connections, MilvusClient, utility)\n",
    "\n",
    "connections.connect(\n",
    "  alias='zillis',\n",
    "  uri=CLUSTER_ENDPOINT,\n",
    "  token=TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acab1da-7b41-452e-bd3d-7b3e1032c57d",
   "metadata": {},
   "source": [
    "## Run the RAG workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1f5f168-7ae8-4ca0-80ad-589779b286f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "#with open(text_path, 'rb') as f:\n",
    "#    text = pickle.load(f)\n",
    "\n",
    "\n",
    "# if table_path != \"\" :\n",
    "#     with open(table_path, 'rb') as f:\n",
    "#         table = pickle.load(f)\n",
    "\n",
    "#if figure_path != \"\" :\n",
    "\n",
    "with open(figure_path, 'rb') as f:\n",
    "    figure = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df387c7b-fcbf-4249-ac76-7e5e3ffd09f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if (table_path != \"\") & (figure_path != \"\") :\n",
    "#     df_combined = pd.concat([pd.DataFrame(text), pd.DataFrame(table), pd.DataFrame(figure)], axis=0, join='outer', ignore_index=True)\n",
    "# elif (table_path == \"\") & (figure_path != \"\") :\n",
    "#     df_combined = pd.concat([pd.DataFrame(text), pd.DataFrame(figure)], axis=0, join='outer', ignore_index=True)\n",
    "# elif (table_path != \"\") & (figure_path == \"\") :\n",
    "#     df_combined = pd.concat([pd.DataFrame(text), pd.DataFrame(table)], axis=0, join='outer', ignore_index=True)\n",
    "# else:\n",
    "\n",
    "df_combined = pd.DataFrame(figure)\n",
    "\n",
    "list_all_title = df_combined['book_title'].unique()\n",
    "    \n",
    "if specify_index_title_to_process == \"all\" :    \n",
    "    title_to_process = list_all_title\n",
    "else : \n",
    "    title_to_process = list_all_title[specify_index_title_to_process]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da66397f-e14d-4110-a247-bd3fdebccbd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 59668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2265759/1795032667.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sequence'] = ''\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"page_num\"] = final_df[\"page_num\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"sequence\"] = final_df[\"sequence\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"position\"] = final_df[\"position\"].fillna(\"\")\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"image_path\"] = final_df[\"image_path\"].fillna(\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 139929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2265759/1795032667.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sequence'] = ''\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"page_num\"] = final_df[\"page_num\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"sequence\"] = final_df[\"sequence\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"position\"] = final_df[\"position\"].fillna(\"\")\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"image_path\"] = final_df[\"image_path\"].fillna(\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 57611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2265759/1795032667.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sequence'] = ''\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"page_num\"] = final_df[\"page_num\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"sequence\"] = final_df[\"sequence\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"position\"] = final_df[\"position\"].fillna(\"\")\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"image_path\"] = final_df[\"image_path\"].fillna(\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num tokens in all context: 76500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_2265759/1795032667.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['sequence'] = ''\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"page_num\"] = final_df[\"page_num\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"sequence\"] = final_df[\"sequence\"].fillna(-1)\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"position\"] = final_df[\"position\"].fillna(\"\")\n",
      "/var/tmp/ipykernel_2265759/1795032667.py:126: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df[\"image_path\"] = final_df[\"image_path\"].fillna(\"\")\n"
     ]
    }
   ],
   "source": [
    "#do in the loop\n",
    "\n",
    "for title in title_to_process : \n",
    "    \n",
    "    df_combined_subset = df_combined[df_combined['book_title']== title]\n",
    "\n",
    "    texts = df_combined_subset['text'].tolist()\n",
    "\n",
    "    concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "        [text for text in texts]\n",
    "    )\n",
    "    print(\n",
    "        \"Num tokens in all context: %s\"\n",
    "        % num_tokens_from_string(concatenated_content, \"cl100k_base\")\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    #### 1. Chunking\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=chunk_size_tok, chunk_overlap=0\n",
    "    )\n",
    "    texts_split = text_splitter.split_text(concatenated_content) \n",
    "    \n",
    "    if apply_chunking is True :\n",
    "        texts = texts_split\n",
    "    \n",
    "    \n",
    "    #### 2. RAPTOR (only done if apply_raptor is True)\n",
    "    if apply_raptor is True : \n",
    "        leaf_texts = texts\n",
    "        import time\n",
    "        start_time3 = time.time()\n",
    "        results = recursive_embed_cluster_summarize(leaf_texts, level=1, n_levels=1)\n",
    "        end_time3 = time.time()\n",
    "\n",
    "        print(f\"Time taken: {end_time3 - start_time3} seconds\")\n",
    "        \n",
    "        initial_clustering = results[1][0].copy()\n",
    "        initial_clustering['cluster'] = initial_clustering['cluster'].apply(lambda x: x[0])\n",
    "        initial_clustering['level'] = 0.0\n",
    "\n",
    "        # Start with the merged initial DataFrame\n",
    "        dfs_to_concat = [df_combined_subset.merge(initial_clustering)] # NOTE!!! to replace with df_combined_subset\n",
    "\n",
    "        # Loop through each level in `results` and collect summary DataFrames\n",
    "        for level_key in sorted(results.keys()):\n",
    "            # Check if `results[level_key]` has a second element (assumed to be summaries)\n",
    "            if results[level_key][0]['text'][0]:  # Check if `results[level_key][1]` exists\n",
    "                summaries_df = pd.DataFrame(results[level_key][1]).rename(columns={\"summaries\": \"text\"})\n",
    "                dfs_to_concat.append(summaries_df)\n",
    "\n",
    "        # Concatenate all DataFrames in the list\n",
    "        final_df = pd.concat(dfs_to_concat, ignore_index=True)\n",
    "        final_df['book_title'] = final_df['book_title'][0]\n",
    "        final_df['embd'] = list(embed(final_df['text']))\n",
    "        \n",
    "        import pandas as pd\n",
    "\n",
    "        # Check if 'sequence' column exists, if not, create it\n",
    "        if 'sequence' not in final_df.columns:\n",
    "            final_df['sequence'] = ''  \n",
    "\n",
    "        if 'image_path' not in final_df.columns:\n",
    "            final_df['image_path']=''\n",
    "            \n",
    "        if 'position' not in final_df.columns:\n",
    "            final_df['position']=''\n",
    "            \n",
    "#         import re\n",
    "#         collection_name = re.sub(r'[- ]', '_', final_df['book_title'][0]) + \"_raptor\"\n",
    "        \n",
    "        import uuid\n",
    "        from langchain.schema import Document\n",
    "\n",
    "        docs = []\n",
    "\n",
    "        final_df[\"page_num\"] = final_df[\"page_num\"].fillna(-1)\n",
    "        final_df[\"sequence\"] = final_df[\"sequence\"].fillna(-1)\n",
    "        final_df[\"position\"] = final_df[\"position\"].fillna(\"\")\n",
    "        final_df[\"cluster\"] = final_df[\"cluster\"].astype(\"int64\")\n",
    "\n",
    "\n",
    "        for _, row in final_df.iterrows():\n",
    "\n",
    "            metadata = {\n",
    "                \"uuid\": str(uuid.uuid4()), \n",
    "                \"book_title\": row[\"book_title\"],\n",
    "                \"page_num\": row[\"page_num\"],\n",
    "                \"cluster\": row[\"cluster\"],\n",
    "                \"level\": row[\"level\"],\n",
    "                \"sequence\": row[\"sequence\"],\n",
    "                \"image_path\": row[\"image_path\"]\n",
    "            }\n",
    "            doc = Document(page_content=row[\"text\"], metadata=metadata)\n",
    "            docs.append(doc)\n",
    "            \n",
    "        collection_name = collection_base_name + '_raptor'\n",
    "\n",
    "\n",
    "   \n",
    "            \n",
    "    #### 2b. If not applying Raptor        \n",
    "            \n",
    "    else :\n",
    "        final_df = df_combined_subset\n",
    "        \n",
    "        if 'sequence' not in final_df.columns:\n",
    "            final_df['sequence'] = ''  \n",
    "\n",
    "        if 'image_path' not in final_df.columns:\n",
    "            final_df['image_path']=''\n",
    "            \n",
    "#         import re\n",
    "#         collection_name = re.sub(r'[- ]', '_', final_df['book_title'][0])\n",
    "        \n",
    "        import uuid\n",
    "        from langchain.schema import Document\n",
    "\n",
    "        docs = []\n",
    "\n",
    "        final_df[\"page_num\"] = final_df[\"page_num\"].fillna(-1)\n",
    "        final_df[\"sequence\"] = final_df[\"sequence\"].fillna(-1)\n",
    "        final_df[\"position\"] = final_df[\"position\"].fillna(\"\")\n",
    "        final_df[\"image_path\"] = final_df[\"image_path\"].fillna(\"\")\n",
    "\n",
    "        for _, row in final_df.iterrows():\n",
    "\n",
    "            metadata = {\n",
    "                \"uuid\": str(uuid.uuid4()), \n",
    "                \"book_title\": row[\"book_title\"],\n",
    "                \"page_num\": row[\"page_num\"],\n",
    "                \"sequence\": row[\"sequence\"],\n",
    "                \"image_path\": row[\"image_path\"]\n",
    "            }\n",
    "            doc = Document(page_content=row[\"text\"], metadata=metadata)\n",
    "            docs.append(doc)\n",
    "        \n",
    "        collection_name = collection_base_name\n",
    "\n",
    "    #### 3. Push to Milvus\n",
    "    \n",
    "    vectorstore = Milvus.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embed_model,\n",
    "        connection_args={\"uri\": CLUSTER_ENDPOINT, \"token\":TOKEN},\n",
    "        consistency_level=\"Strong\",\n",
    "        collection_name = collection_name,\n",
    "        index_params={\"metric_type\": \"COSINE\", \"index_type\": \"AUTOINDEX\", \"params\": {}}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e44450db-6ad3-4850-b332-3914f3be90e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>page_num</th>\n",
       "      <th>position</th>\n",
       "      <th>text</th>\n",
       "      <th>image_path</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>6</td>\n",
       "      <td>(842.519039577908, 860.0380791558159, 1517.716...</td>\n",
       "      <td>Fig. 1.1 Illustrations of normal segmental ana...</td>\n",
       "      <td>./Radiology Illustrated_ Hepatobiliary and Pan...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>7</td>\n",
       "      <td>(842.5167507595486, 765.6958685980903, 1517.71...</td>\n",
       "      <td>Fig. 1.2 Agenesis of the right lobe of the liv...</td>\n",
       "      <td>./Radiology Illustrated_ Hepatobiliary and Pan...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>8</td>\n",
       "      <td>(842.5182766384548, 1261.75537109375, 1517.713...</td>\n",
       "      <td>Fig. 1.3 Agenesis of the left lateral segment ...</td>\n",
       "      <td>./Radiology Illustrated_ Hepatobiliary and Pan...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>9</td>\n",
       "      <td>(842.5194634331597, 1576.3349745008682, 1517.7...</td>\n",
       "      <td>Fig. 1.4 Hypoplasia of the left lateral segmen...</td>\n",
       "      <td>./Radiology Illustrated_ Hepatobiliary and Pan...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>10</td>\n",
       "      <td>(842.518530951606, 766.8392605251736, 1517.774...</td>\n",
       "      <td>Fig. 1.5 Hypoplasia of the left medial segment...</td>\n",
       "      <td>./Radiology Illustrated_ Hepatobiliary and Pan...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>811</td>\n",
       "      <td>(1478.4449259440105, 99.48724110921223, 1511.8...</td>\n",
       "      <td>Fig. 26.2  Subcapsular hematoma in a 33-year-o...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>812</td>\n",
       "      <td>(1300.9661356608074, 99.48724110921223, 1511.7...</td>\n",
       "      <td>Fig. 26.3 Splenic laceration in a 17-year-old ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>813</td>\n",
       "      <td>(1477.6989407009548, 99.48724110921223, 1511.8...</td>\n",
       "      <td>Fig. 26.4 Splenic infarction in a four-year-ol...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>815</td>\n",
       "      <td>(843.4371948242188, 1655.9967041015625, 1517.7...</td>\n",
       "      <td>Fig. 26.6 Splenic rupture in a 35-year-old fem...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>Radiology Illustrated_ Hepatobiliary and Pancr...</td>\n",
       "      <td>816</td>\n",
       "      <td>(843.4397379557291, 965.4480828179253, 1517.71...</td>\n",
       "      <td>Fig. 26.7 Postoperative complication in a 53-y...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             book_title  page_num  \\\n",
       "2756  Radiology Illustrated_ Hepatobiliary and Pancr...         6   \n",
       "2757  Radiology Illustrated_ Hepatobiliary and Pancr...         7   \n",
       "2758  Radiology Illustrated_ Hepatobiliary and Pancr...         8   \n",
       "2759  Radiology Illustrated_ Hepatobiliary and Pancr...         9   \n",
       "2760  Radiology Illustrated_ Hepatobiliary and Pancr...        10   \n",
       "...                                                 ...       ...   \n",
       "3261  Radiology Illustrated_ Hepatobiliary and Pancr...       811   \n",
       "3262  Radiology Illustrated_ Hepatobiliary and Pancr...       812   \n",
       "3263  Radiology Illustrated_ Hepatobiliary and Pancr...       813   \n",
       "3264  Radiology Illustrated_ Hepatobiliary and Pancr...       815   \n",
       "3265  Radiology Illustrated_ Hepatobiliary and Pancr...       816   \n",
       "\n",
       "                                               position  \\\n",
       "2756  (842.519039577908, 860.0380791558159, 1517.716...   \n",
       "2757  (842.5167507595486, 765.6958685980903, 1517.71...   \n",
       "2758  (842.5182766384548, 1261.75537109375, 1517.713...   \n",
       "2759  (842.5194634331597, 1576.3349745008682, 1517.7...   \n",
       "2760  (842.518530951606, 766.8392605251736, 1517.774...   \n",
       "...                                                 ...   \n",
       "3261  (1478.4449259440105, 99.48724110921223, 1511.8...   \n",
       "3262  (1300.9661356608074, 99.48724110921223, 1511.7...   \n",
       "3263  (1477.6989407009548, 99.48724110921223, 1511.8...   \n",
       "3264  (843.4371948242188, 1655.9967041015625, 1517.7...   \n",
       "3265  (843.4397379557291, 965.4480828179253, 1517.71...   \n",
       "\n",
       "                                                   text  \\\n",
       "2756  Fig. 1.1 Illustrations of normal segmental ana...   \n",
       "2757  Fig. 1.2 Agenesis of the right lobe of the liv...   \n",
       "2758  Fig. 1.3 Agenesis of the left lateral segment ...   \n",
       "2759  Fig. 1.4 Hypoplasia of the left lateral segmen...   \n",
       "2760  Fig. 1.5 Hypoplasia of the left medial segment...   \n",
       "...                                                 ...   \n",
       "3261  Fig. 26.2  Subcapsular hematoma in a 33-year-o...   \n",
       "3262  Fig. 26.3 Splenic laceration in a 17-year-old ...   \n",
       "3263  Fig. 26.4 Splenic infarction in a four-year-ol...   \n",
       "3264  Fig. 26.6 Splenic rupture in a 35-year-old fem...   \n",
       "3265  Fig. 26.7 Postoperative complication in a 53-y...   \n",
       "\n",
       "                                             image_path sequence  \n",
       "2756  ./Radiology Illustrated_ Hepatobiliary and Pan...           \n",
       "2757  ./Radiology Illustrated_ Hepatobiliary and Pan...           \n",
       "2758  ./Radiology Illustrated_ Hepatobiliary and Pan...           \n",
       "2759  ./Radiology Illustrated_ Hepatobiliary and Pan...           \n",
       "2760  ./Radiology Illustrated_ Hepatobiliary and Pan...           \n",
       "...                                                 ...      ...  \n",
       "3261                                                              \n",
       "3262                                                              \n",
       "3263                                                              \n",
       "3264                                                              \n",
       "3265                                                              \n",
       "\n",
       "[510 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c947c-76b0-409b-a053-a8fde8471500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "clean_env",
   "name": "tf2-cpu.2-11.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m119"
  },
  "kernelspec": {
   "display_name": "clean_env",
   "language": "python",
   "name": "clean_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
